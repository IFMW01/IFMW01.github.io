<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Israel Mason Williams | Publications</title>
  <meta name="description" content="Personal website of Israel Mason-Williams.">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">

  <!-- Scripts -->
  <script async src="https://badge.dimensions.ai/badge.js" charset="utf-8"></script>
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Israel</span> Mason-Williams</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
            
          
            
              <li class="nav-item ">
                  <a class="nav-link" href="/cv/">
                    cv
                    
                  </a>
              </li>
            
          
            
          
            
              <!-- <li class="nav-item ">
                  <a class="nav-link" href="/projects/">
                    projects
                    
                  </a>
              </li> -->
            
          
            
              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="/publications/">
                    publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>
            
          
            
              <!-- <li class="nav-item ">
                  <a class="nav-link" href="/teaching/">
                    teaching
                    
                  </a>
              </li> -->
            
          
            
          
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>Publications</h1>
  <h6><span><b>*</b></span> denotes equal contribution and joint lead authorship.</h6>



<div class="row m-0 p-0" style="border-bottom: 1px solid #ddd;">
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://scienceofdlworkshop.github.io" target="_blank">
          NeurIPS
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="StengelEskin-2022-troubling_quirk" class="col p-0">
      <h5 class="title mb-0">Knowledge Distilation: The Functional Perspective</h5>
      <div class="author">
                
        <nobr><em>Israel Mason-Williams</em>,</nobr>        
            
        <nobr><a href="https://gmw99.github.io" target="_blank">Gabryel Mason-Williams<b>*</b></a>,</nobr>

        and

        <nobr><a href="https://scholar.google.co.uk/citations?hl=en&user=W-gexv0AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Mark Sandler</a>.</nobr>
              
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Workshop on Science of Deep Learning at NeurIPS.
          
          
            2024.
          
        </p>
      </div>

      
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#kd-2024-abstract" role="button" aria-expanded="false" aria-controls="kd-2024-abstract">Abstract</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/NeurIPS2024/Knowledge_Distillation-The_Functional_Perspective_2024.pdf" target="_blank">PDF</a>
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="kd-2024-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
              Empirical findings of accuracy correlations between students and teachers in the knowledge distillation framework have served as supporting evidence for knowledge transfer. In this paper, we sought to explain and understand the knowledge transfer derived from knowledge distillation via functional similarity, hypothesising that knowledge distillation provides a functionally similar student to its teacher model. While we accept this hypothesis for two out of three architectures across a range of metrics for functional analysis against four controls, the results show that knowledge transfer is significant but it is less pronounced than expected for conditions that maximise opportunities for functional similarity. Furthermore, results from the use of Uniform and Gaussian Noise as teachers suggest that the knowledge-sharing aspects of knowledge distillation inadequately describe the accuracy benefits witnessed when using the knowledge distillation training setup itself. Moreover, in the first instance, we show that knowledge distillation is not a compression mechanism but primarily a data-dependent training regulariser with a small capacity to transfer knowledge in the best case.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
      <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://scienceofdlworkshop.github.io" target="_blank">
        NeurIPS
      </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="Zhou-2022-online_parsing" class="col p-0">
      <h5 class="title mb-0">Explicit Regularisation, Sharpness and Calibration.</h5>
      <div class="author">
                
          <nobr><em>Israel Mason-Williams</em>,</nobr>        
              
          <nobr><a href="https://www.linkedin.com/in/fredrik-ekholm-503711146/" target="_blank">Fredrik Ekholm<b>*</b></a>,</nobr>

          and

          <nobr><a href="https://scholar.google.com/citations?user=koQCVT4AAAAJ&hl=en" target="_blank">Ferenc Husz√°r</a>.</nobr>
                
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Workshop on Science of Deep Learning at NeurIPS.
            

            2024.
          
        </p>
      </div>

      
      <!-- <div style="color: #FFC000;"><p class="periodical font-italic"><i class="fa fa-solid fa-star"></i> Outstanding Paper Award!</p></div> -->
      
  
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#Mason-Williams-loss-abstract" role="button" aria-expanded="false" aria-controls="Mason-Williams-loss-abstract">Abstract</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/NeurIPS2024/Explicit_Regularisation_Sharpness.pdf" target="_blank">PDF</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/IFMW01/Explicit-Regularisation-Sharpness-and-Calibration-Submission" target="_blank">Code</a>
        
        
        <!-- 
          <div
            class="__dimensions_badge_embed__"
            data-doi="10.18653/v1/2022.acl-long.110"
            data-hide-zero-citations="true"
            data-style="small_rectangle"
            data-legend="hover-right"
            style="display: inline-block; margin-bottom: 10px;"
          ></div>
         -->
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="Mason-Williams-loss-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
             We probe the relation between flatness, generalisation and calibration in neural networks, using explicit regularisation as a control variable. Our findings indicate that the range of flatness metrics surveyed fail to positively correlate with variation in generalisation or calibration. In fact, the correlation is often opposite to what has been hypothesized or claimed in prior work, with calibrated models typically existing at sharper minima compared to relative baselines, this relation exists across model classes and dataset complexities.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li>
<li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
      <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 53px;" href="https://pml4dc.github.io/iclr2024/" target="_blank">
        ICLR
      </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="Chen-2022-text_to_sql" class="col p-0">
      <h5 class="title mb-0">Neural Network Compression: The Functional Perspective.</h5>
      <div class="author">
        
                <nobr><em>Israel Mason-Williams</em>.</nobr>        
          
      </div>

      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#Mason-Willians-2024-ICLR_FUNC-abstract" role="button" aria-expanded="false" aria-controls="Mason-Willians-2024-ICLR_FUNC-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/ICLR2024/NEURAL_NETWORK_COMPRESSION.pdf" target="_blank">PDF</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/IFMW01/L46_ifm24" target="_blank">Code</a>
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="Mason-Willians-2024-ICLR_FUNC-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
              Compression techniques, such as Knowledge distillation, Pruning, and Quantiza- tion reduce the computational costs of model inference and enable on-edge ma- chine learning. The efficacy of compression methods is often evaluated through the proxy of accuracy and loss to understand similarity of the compressed model. This study aims to explore the functional divergence between compressed and uncompressed models. The results indicate that Quantization and Pruning create models that are functionally similar to the original model. In contrast, Knowl- edge distillation creates models that do not functionally approximate their teacher models. The compressed model resembles the dissimilarity of function observed in independently trained models. Therefore, it is verified, via a functional under- standing, that Knowledge distillation is not a compression method. Thus, leading to the definition of Knowledge distillation as a training regulariser given that no knowledge is distilled from a teacher to a student.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
    <div class="col-sm-1 align-self-end mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2024</h3>
    </div>
  </div>

  </div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2025 Israel Mason-Williams.
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-54519238-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
